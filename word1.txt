import lxml
from lxml import html
from lxml.html import HtmlElement, etree
from lxml.html.clean import Cleaner
from urllib import request


def connect(url):

    def get_http_headers():
        version_info = (1, 0, 25)
        __version__ = ".".join(map(str, version_info))
        browser_user_agent = 'Parser/%s' % __version__
        headers = {'User-agent': browser_user_agent}
        return headers

    try:
        req = request.Request(url,
                              headers=get_http_headers())
        res = request.urlopen(req, timeout=30)
        if res is not None:
            return res.read()
    except Exception as err:
        print(err)


def retrieve_html(url):
    raw_html = connect(url)
    # tree = lxml.html.etree.fromstring(raw_html)
    # print(tree)
    # print(type(tree))
    # tree = lxml.html.etree.fromstring(raw_html)
    return lxml.html.fromstring(raw_html)


def clean(doc):
    return Cleaner(
        scripts=True,
        javascript=True,
        style=True,
        comments=True,
        forms=True,
        frames=True,
        embedded=True,
        # meta=True,
        remove_unknown_tags=True,
        kill_tags=(
            'form',
            'img',
            'button'
        ),
        # remove_tags=(
        #     'span'
        # ),
    ).clean_html(doc)



def traverse(doc):
    # nodes to check == div, tr, p,
    if isinstance(doc, HtmlElement):
        # tree = doc.getchildren()
        tree = doc.getroottree()
        print(type(tree))
        print('\n')
        for node in tree.iter():
            pass
    return doc


def remove_link_dense(doc):
    tags = ['div', 'span', 'tr', 'p']
    if isinstance(doc, HtmlElement):
        remove_nodes = []
        for node in doc.iter(*tags):
            a_words = float(sum([len(a.text.split()) for a in node.iter('a') if a.text]))
            word_count = float(sum([len(t.text.split()) for t in node.iter() if t.text]))
            if word_count == a_words != 0:
                remove_nodes.append(node)
        for node in remove_nodes:
            node.getparent().remove(node)
    return doc


def noise_removal(url):
    doc = retrieve_html(url)
    if isinstance(doc, HtmlElement):
        doc = clean(doc)
        doc = remove_link_dense(doc)
        # print(doc.text_content())
    return doc


def run_main():
    url = 'https://edition.cnn.com/2012/02/22/world/europe/uk-occupy-london/index.html'
    doc = noise_removal(url)
    print(doc.text_content())


if __name__ == '__main__':
    run_main()
